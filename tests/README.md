# DALIA Testing Framework

This directory contains the comprehensive test suite for the DALIA framework, organized according to the **testing pyramid** principle.

## ğŸ—ï¸ **Test Architecture Overview**

```
                    ğŸ”º
                   /   \
              integration/     â† Few, expensive, end-to-end tests
                 /       \
        component_integration/  â† Medium, component interaction tests
               /           \
              /    unit/    \   â† Many, fast, isolated tests
             /_______________\
```

## ğŸ“ **Directory Structure**

### [`unit/`](unit/README.md) - **Fast, Isolated Tests**
- **Purpose**: Test individual components in isolation
- **Speed**: < 100ms per test (typically)
- **Dependencies**: Minimal (mocked when needed)
- **Quantity**: Many (hundreds to thousands)

**Examples**: Configuration validation, utility functions, error handling

### [`component_integration/`](component_integration/README.md) - **Component Interaction Tests**  
- **Purpose**: Test interactions within or between closely related components
- **Speed**: 100ms - 5s per test
- **Dependencies**: Real system resources (MPI, GPU, files)
- **Quantity**: Medium (dozens to hundreds)

**Examples**: MPI communication, GPU kernels, backend compatibility

### [`integration/`](integration/README.md) - **End-to-End Workflow Tests**
- **Purpose**: Test complete user workflows and multi-component interactions
- **Speed**: Minutes to hours per test
- **Dependencies**: Full system setup + datasets
- **Quantity**: Few (tens)

**Examples**: Complete Gaussian Process workflows, performance benchmarks, scientific accuracy

## ğŸš€ **Running Tests**

### Quick Development Testing
```bash
# Run fast unit tests only
python -m pytest tests/unit/ -v

# Run tests for specific component
python -m pytest tests/unit/communicator/ -v

# Use standalone runner for rapid iteration
python tests/unit/communicator/runner.py
```

### Comprehensive Testing
```bash
# Run all tests (slow!)
python -m pytest tests/ -v

# Run unit + component integration (skip slow integration)
python -m pytest tests/unit/ tests/component_integration/ -v

# Run with coverage
python -m pytest tests/unit/ --cov=src/dalia --cov-report=html
```

### CI/CD Pipeline Testing
```bash
# Fast feedback loop (< 30 seconds)
python -m pytest tests/unit/ -x

# Medium verification (< 5 minutes)  
python -m pytest tests/unit/ tests/component_integration/ -x

# Full verification (nightly, pre-release)
python -m pytest tests/ --timeout=3600
```

## ğŸ¯ **When to Add Tests Where**

### Add to `unit/` when:
- âœ… Testing pure logic without external dependencies
- âœ… Validating configuration and input parsing
- âœ… Testing error conditions and edge cases
- âœ… Verifying utility functions and calculations

### Add to `component_integration/` when:
- âœ… Testing real MPI communication
- âœ… Testing actual GPU operations
- âœ… Testing file I/O and data persistence
- âœ… Testing cross-backend compatibility
- âœ… Testing hardware detection and initialization

### Add to `integration/` when:
- âœ… Testing complete user workflows
- âœ… Validating scientific accuracy end-to-end
- âœ… Testing performance and scalability
- âœ… Verifying multiple components working together
- âœ… Testing example code and documentation

## ğŸ“Š **Current Test Status**

| Component | Unit Tests | Component Integration | Integration |
|-----------|------------|----------------------|-------------|
| Communicator | âœ… Complete | âœ… Complete | ğŸš§ Planned |
| Solvers | ğŸš§ Planned | ğŸš§ Planned | ğŸš§ Planned |
| Kernels | ğŸš§ Planned | ğŸš§ Planned | ğŸš§ Planned |
| Models | ğŸš§ Planned | ğŸš§ Planned | ğŸš§ Planned |

## ğŸ› ï¸ **Development Guidelines**

1. **Follow the pyramid**: More unit tests, fewer integration tests
2. **Start with unit tests** when adding new functionality
3. **Mock external dependencies** in unit tests
4. **Use real dependencies** in component/integration tests
5. **Skip gracefully** when hardware/software unavailable:
   ```python
   @pytest.mark.skipif(not backend_flags["mpi_avail"], reason="MPI not available")
   ```
6. **Clean up resources** (files, GPU memory, MPI communicators)
7. **Use descriptive test names** that explain what's being tested

## ğŸ”§ **Test Configuration**

### Pytest Configuration (`pyproject.toml` or `pytest.ini`)
```ini
[tool.pytest.ini_options]
testpaths = ["tests"]
markers = [
    "slow: marks tests as slow (> 30 seconds)",
    "gpu_required: marks tests that require GPU",
    "multi_node: marks tests that require multiple nodes",
    "large_memory: marks tests that require > 16GB RAM"
]
```

### Environment Variables
```bash
export MPI_CUDA_AWARE=1    # Enable CUDA-aware MPI testing
export USE_NCCL=1          # Enable NCCL testing  
export ARRAY_MODULE=cupy   # Use CuPy for GPU tests
```

## ğŸ“ˆ **Contributing New Tests**

When adding new functionality:

1. **Start with unit tests** in `tests/unit/[component]/`
2. **Add component integration tests** if using real system resources
3. **Consider integration tests** for user-facing workflows
4. **Update relevant README files** when adding new test categories
5. **Use appropriate pytest markers** for test categorization

## ğŸª **Example Component Test Structure**

```
tests/
â”œâ”€â”€ unit/
â”‚   â””â”€â”€ new_component/
â”‚       â”œâ”€â”€ conftest.py
â”‚       â”œâ”€â”€ test_basic.py
â”‚       â”œâ”€â”€ test_config.py
â”‚       â””â”€â”€ runner.py
â”œâ”€â”€ component_integration/
â”‚   â””â”€â”€ new_component/
â”‚       â”œâ”€â”€ conftest.py
â”‚       â”œâ”€â”€ test_hardware_integration.py
â”‚       â””â”€â”€ test_cross_backend.py
â””â”€â”€ integration/
    â””â”€â”€ test_new_component_workflows.py
```

This structure ensures comprehensive testing while maintaining fast development feedback loops! ğŸ¯
